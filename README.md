# SPEECH-EMOTION-RECOGNITION
## Introduction
Speech Emotion Recognition (SER) is the process of trying to recognise human emotion and effective states from speech. Speech emotion recognition is a very interesting yet very challenging task of human computer interaction. In recent years this topic has grabbed so much attention. In the field of speech emotion recognition many techniques have been utilized to extract emotions from signals, including many wellestablished speech analysis and classification techniques. In the traditional way of speech emotion recognition features are extracted from the speech signals and then the features are selected which is collectively known as a selection module and then the emotions are recognized. This is a very lengthy and time taking process so this project gives an overview of the machine learning technique which is based on a simple algorithm based on feature extraction and model creation which recognizes the emotion.
## Objective
The aim of the project is about the detection of the emotions elicited by the speaker while talking. As an example, speech produced in a state of fear, anger, or joy becomes loud and fast, with a higher and wider range in pitch, whereas emotions such as sadness or tiredness generate slow and low-pitched speech. Detection of human emotions through voicepattern and speech-pattern analysis has many applications such as better assisting human-machine interactions. To recognize emotions based on speech i.e., the audio files, Input will be the audio files and the output will be different kinds of emotions. Based on the voice modulation, pitch and other audio attributes, we are going to classify which emotion it conducts.
## Scope
Emotions play an extremely important role in human mental life. It is a medium of expression of one's perspective or one's mental state to others. Speech Emotion Recognition (SER) can be defined as extraction of the emotional state of the speaker from his or her speech signal.                                                  
### WHY DO WE NEED IT?                                                                                                                                                
1. Emotion recognition is the part of speech recognition which is gaining more popularity and need for it increases enormously. This project attempts to use machine learning to recognize the emotions from data.                                                                                                                          
2. SER(Speech Emotion Recognition) is used in call centre for classifying calls according to emotions and can be used as the performance parameter for conversational analysis thus identifying the unsatisfied customer, customer satisfaction and so on.. for helping companies improving their services                                   
3. It can also be used in-car board systems based on information of the mental state of the driver can be provided to the system to initiate his/her safety preventing accidents from happening.
## About the dataset
The data set is extracted from Kaggle and the name of the data set is Toronto emotional speech set(TESS). There are a set of 200 target words were spoken in the carrier phrase "Say the word _' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions (anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral). There are 2800 data points (audio files) in total. The dataset is organized such that each of the two female actors and their emotions are contained within its own folder. And within that, all 200 target words audio files can be found. The format of the audio file is a WAV format.
